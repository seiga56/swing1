import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import subprocess
import os
import uuid

# --- 1. å®šæ•°ã¨åˆæœŸåŒ– ---
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

# --- 2. åˆ†æãƒ­ã‚¸ãƒƒã‚¯é–¢æ•° ---

def calculate_angle(a, b, c):
    """3ç‚¹ a, b, c ã‚’å—ã‘å–ã‚Šã€b ã‚’é ‚ç‚¹ã¨ã™ã‚‹è§’åº¦ï¼ˆåº¦æ•°ï¼‰ã‚’è¨ˆç®—ã™ã‚‹"""
    a, b, c = np.array(a), np.array(b), np.array(c)
    ba, bc = a - b, c - b
    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))
    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))
    return np.degrees(angle)

def calculate_rotation_angle(p_left, p_right):
    """å·¦å³ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‹ã‚‰æ°´å¹³ç·šã«å¯¾ã™ã‚‹å‚¾ãè§’åº¦ã‚’è¨ˆç®—ã™ã‚‹"""
    p_left, p_right = np.array(p_left), np.array(p_right)
    connect_vector = p_right - p_left
    angle_rad = np.arctan2(connect_vector[1], connect_vector[0])
    return np.degrees(angle_rad)

@st.cache_data
def process_video_for_analysis(video_path, label):
    """å‹•ç”»è§£æã€ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã€è§£æå‹•ç”»ç”Ÿæˆã‚’ä¸€æ‹¬ã§å®Ÿè¡Œã™ã‚‹ã‚³ã‚¢é–¢æ•°"""
    
    st.info(f"âŒ› {label} ã®å‹•ç”»è§£æä¸­ã§ã™...")
    
    data_to_save = []
    
    # ä¸€æ„ãªåå‰ã‚’ä»˜ã‘ã¦ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
    temp_raw_path = f"temp_raw_{uuid.uuid4()}.mp4"
    temp_analysis_path = f"temp_analysis_{uuid.uuid4()}.mp4"
    
    # é©åˆ‡ãªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨ï¼ˆæ‰‹å‹•ä¿®æ­£ã®çµŒé¨“ã‚’æ´»ã‹ã™ï¼‰
    # Streamlit Cloudã§ã¯å‹•ç”»ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒå®‰å®šã—ãªã„ãŸã‚ã€è‡ªå‹•å›è»¢ã¯è¡Œã‚ãªã„ã“ã¨ãŒå¤šã„
    FILTERS = 'transpose=2,vflip,hflip' # ã“ã‚Œã¾ã§ã®å¤±æ•—ã‹ã‚‰æœ€ã‚‚å¯èƒ½æ€§ã®é«˜ã„ãƒ‘ã‚¿ãƒ¼ãƒ³
    
    with mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ« {video_path} ã‚’é–‹ã‘ã¾ã›ã‚“ã€‚")
            return None, None

        # å‹•ç”»æ›¸ãå‡ºã—è¨­å®š
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        # ç”Ÿã®è§£æå‹•ç”»ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãå‡ºã—
        out = cv2.VideoWriter(temp_raw_path, fourcc, fps, (width, height))
        
        frame_num = 0
        while cap.isOpened():
            success, image = cap.read()
            if not success: break
            
            image.flags.writeable = False
            results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            image.flags.writeable = True

            if results.pose_landmarks:
                try:
                    # è‚˜ã®è§’åº¦
                    r_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]
                    r_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]
                    r_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]
                    r_elbow_angle = calculate_angle(r_shoulder, r_elbow, r_wrist)

                    # è‚©ã®å‚¾ã
                    l_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]
                    shoulder_tilt = calculate_rotation_angle(l_shoulder, r_shoulder) 

                    # è…°ã®å‚¾ã
                    l_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]
                    r_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]
                    hip_tilt = calculate_rotation_angle(l_hip, r_hip) 
                    
                    data_to_save.append({'Frame': frame_num, 'Elbow_Angle': r_elbow_angle, 'Shoulder_Tilt': shoulder_tilt, 'Hip_Tilt': hip_tilt})
                    
                    # éª¨æ ¼ã®æç”»
                    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
                except Exception as e:
                    # æ¤œå‡ºã‚¨ãƒ©ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    pass
            
            out.write(image)
            frame_num += 1
            
        cap.release()
        out.release()
        
    # ffmpegã«ã‚ˆã‚‹å‘ãã®ä¿®æ­£ã¨æœ€çµ‚å‡ºåŠ›
    try:
        subprocess.run(['ffmpeg', 
                        '-i', temp_raw_path, 
                        '-vf', FILTERS, # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
                        '-c:v', 'libx264', '-crf', '23', '-y', temp_analysis_path], 
                       check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        os.remove(temp_raw_path) # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    except subprocess.CalledProcessError as e:
        st.warning(f"âš ï¸ å‹•ç”»ã®å‘ãä¿®æ­£ã‚¨ãƒ©ãƒ¼ã€‚å…ƒã®è§£æå‹•ç”»ã‚’ãã®ã¾ã¾è¡¨ç¤ºã—ã¾ã™ã€‚")
        temp_analysis_path = temp_raw_path

    df = pd.DataFrame(data_to_save)
    return df, temp_analysis_path

def plot_comparison(df_ref, df_user, metric, title):
    """æ‰‹æœ¬ã¨è‡ªåˆ†ã®ã‚¹ã‚¤ãƒ³ã‚°ã®æŒ‡æ¨™ã‚’æ¯”è¼ƒã‚°ãƒ©ãƒ•ã¨ã—ã¦æç”»ã™ã‚‹"""
    fig, ax = plt.subplots(figsize=(10, 5))
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã«åˆã‚ã›ã¦é©åˆ‡ã«ãƒ—ãƒ­ãƒƒãƒˆ
    ax.plot(df_user['Frame'], df_user[metric], label='è‡ªåˆ†ã®ã‚¹ã‚¤ãƒ³ã‚° (é’ç·š)', color='blue', linestyle='-')
    ax.plot(df_ref['Frame'], df_ref[metric], label='æ‰‹æœ¬ã‚¹ã‚¤ãƒ³ã‚° (èµ¤ç ´ç·š)', color='red', linestyle='--')
    
    ax.set_xlabel('ãƒ•ãƒ¬ãƒ¼ãƒ æ•° (æ™‚é–“çµŒé)')
    ax.set_ylabel(metric)
    ax.set_title(title)
    ax.legend()
    ax.grid(True, linestyle='--', alpha=0.6)
    return fig

def generate_swing_feedback(df_ref, df_user):
    """ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦è‡ªå‹•ã§æ”¹å–„ç‚¹ã‚’æŒ‡æ‘˜ã™ã‚‹"""
    feedback = ["\n--- ğŸ¤– è‡ªå‹•ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆAIåˆ†æã«åŸºã¥ãå®¢è¦³çš„è©•ä¾¡ï¼‰ ---"]
    
    # 1. è‚˜ã®ã‚¿ãƒ¡ï¼ˆæœ€å°è§’åº¦ï¼‰æ¯”è¼ƒ
    min_angle_ref = df_ref['Elbow_Angle'].min()
    min_angle_user = df_user['Elbow_Angle'].min()
    diff_elbow = min_angle_user - min_angle_ref
    
    if diff_elbow > 10:
        feedback.append(f"âš ï¸ **è‚˜ã®ã‚¿ãƒ¡ä¸è¶³ã®å¯èƒ½æ€§:** ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆæ™‚ã®æœ€å°è‚˜è§’åº¦ãŒæ‰‹æœ¬ã‚ˆã‚Šç´„ {diff_elbow:.1f}åº¦ æµ…ã„ã§ã™ã€‚ã‚¿ãƒ¡ã‚’æ·±ãã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šå¼·ã„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãŒæœŸå¾…ã§ãã¾ã™ã€‚")
    elif diff_elbow < -10:
        feedback.append(f"âœ… è‚˜ã®ã‚¿ãƒ¡ãŒæ‰‹æœ¬ã‚ˆã‚Šã‚‚æ·±ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒªãƒªãƒ¼ã‚¹ãŒé…ã‚Œã¦ã„ãªã„ã‹ç¢ºèªã—ã¾ã—ã‚‡ã†ã€‚")

    # 2. è‚©ã®å‚¾ãï¼ˆå®‰å®šæ€§ï¼‰æ¯”è¼ƒ
    std_shoulder_user = df_user['Shoulder_Tilt'].std()
    std_shoulder_ref = df_ref['Shoulder_Tilt'].std()
    
    if std_shoulder_user > std_shoulder_ref * 1.5:
        feedback.append(f"â—ï¸ **è‚©ã®è»¸ã®ä¸å®‰å®šæ€§:** è‚©ã®å‚¾ãï¼ˆãƒãƒ«ãƒˆï¼‰ã®å¤‰å‹•ãŒæ‰‹æœ¬ã‚ˆã‚Šå¤§ããã€è»¸ãŒãƒ–ãƒ¬ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚¹ã‚¤ãƒ³ã‚°ä¸­ã®é ­ã®ä½ç½®ã‚’æ„è­˜ã—ã¾ã—ã‚‡ã†ã€‚")
    
    if len(feedback) == 1:
         feedback.append("âœ¨ **ç¾æ™‚ç‚¹ã§ã¯å¤§ããªèª²é¡Œã¯è¦‹ã‚‰ã‚Œã¾ã›ã‚“ã€‚** ã‚°ãƒ©ãƒ•ã§ç´°ã‹ã„ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®ã‚ºãƒ¬ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    return "\n".join(feedback)


# --- 3. Streamlitã‚¢ãƒ—ãƒªã®æ§‹æˆ ---

st.set_page_config(page_title="AIã‚¹ã‚¤ãƒ³ã‚°åˆ†æãƒ‡ãƒ¢", layout="wide")
st.title("âš¾ï¸ AIã‚¹ã‚¤ãƒ³ã‚°åˆ†æã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¢ã‚¢ãƒ—ãƒª")
st.markdown("### MediaPipe Poseã«ã‚ˆã‚‹å®¢è¦³çš„ãªã‚¹ã‚¤ãƒ³ã‚°æ¯”è¼ƒ")

# æ‰‹æœ¬å‹•ç”»ã¯äº‹å‰ã«ãƒªãƒã‚¸ãƒˆãƒªã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ã¨ã™ã‚‹
REF_VIDEO_PATH = 'my_swing.mp4' 

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å‹•ç”»ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
st.sidebar.header("ã‚¹ãƒ†ãƒƒãƒ— 1: å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
uploaded_file = st.sidebar.file_uploader("æ¯”è¼ƒã—ãŸã„å‹•ç”» (è‡ªåˆ†ã®ã‚¹ã‚¤ãƒ³ã‚°) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["mp4", "mov"])

if uploaded_file is not None:
    # --- å‡¦ç†é–‹å§‹ ---
    
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚çš„ã«ä¿å­˜
    temp_user_path = f"temp_user_{uuid.uuid4()}.mp4"
    with open(temp_user_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    st.sidebar.success("å‹•ç”»ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    # æ‰‹æœ¬å‹•ç”»ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼å‹•ç”»ã®è§£æã‚’å®Ÿè¡Œ (ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨)
    try:
        df_ref, ref_video_path = process_video_for_analysis(REF_VIDEO_PATH, "æ‰‹æœ¬ã‚¹ã‚¤ãƒ³ã‚°")
        df_user, user_video_path = process_video_for_analysis(temp_user_path, "è‡ªåˆ†ã®ã‚¹ã‚¤ãƒ³ã‚°")

        if df_ref is not None and df_user is not None:
            
            # --- çµæœã®è¡¨ç¤º ---
            st.header("1. è§£æå‹•ç”»ã®æ¯”è¼ƒ")
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("æ‰‹æœ¬ã‚¹ã‚¤ãƒ³ã‚° (ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹)")
                st.video(ref_video_path)
            
            with col2:
                st.subheader("è‡ªåˆ†ã®ã‚¹ã‚¤ãƒ³ã‚° (è§£ææ¸ˆã¿)")
                st.video(user_video_path)

            st.header("2. è‡ªå‹•ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
            feedback = generate_swing_feedback(df_ref, df_user)
            st.markdown(feedback)

            st.header("3. æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®æ¯”è¼ƒã‚°ãƒ©ãƒ•")
            
            st.subheader("å³è‚˜ã®è§’åº¦å¤‰åŒ– (Elbow Angle)")
            fig_elbow = plot_comparison(df_ref, df_user, 'Elbow_Angle', 'å³è‚˜ã®è§’åº¦å¤‰åŒ– (Elbow Angle)')
            st.pyplot(fig_elbow)
            
            st.subheader("è‚©ã®å‚¾ãå¤‰åŒ– (Shoulder Tilt)")
            fig_shoulder = plot_comparison(df_ref, df_user, 'Shoulder_Tilt', 'è‚©ã®å‚¾ãå¤‰åŒ– (Shoulder Tilt)')
            st.pyplot(fig_shoulder)
            
            st.subheader("è…°ã®å‚¾ãå¤‰åŒ– (Hip Tilt)")
            fig_hip = plot_comparison(df_ref, df_user, 'Hip_Tilt', 'è…°ã®å‚¾ãå¤‰åŒ– (Hip Tilt)')
            st.pyplot(fig_hip)

            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if os.path.exists(temp_user_path):
                os.remove(temp_user_path)
            if os.path.exists(ref_video_path):
                os.remove(ref_video_path)
            if os.path.exists(user_video_path):
                os.remove(user_video_path)
                
        else:
            st.error("å‹•ç”»è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ã„å½¢å¼ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            
    except Exception as e:
        st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

else:
    st.info("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€AIã‚¹ã‚¤ãƒ³ã‚°åˆ†æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")